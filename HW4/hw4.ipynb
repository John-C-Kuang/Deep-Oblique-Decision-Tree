{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils import ml_utils\n",
    "from typing import Callable, Union, Any\n",
    "\n",
    "from tqdm.contrib.itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     popularity  duration_ms  explicit  danceability  energy  key  loudness  \\\n",
      "0             0       169756     False         0.601   0.713    4    -3.758   \n",
      "1            66        87133     False         0.638   0.324    0    -7.787   \n",
      "2             1       242640     False         0.660   0.752    6    -5.839   \n",
      "3            71       242628     False         0.697   0.663    6    -7.246   \n",
      "4             0       214733     False         0.552   0.823    2    -5.988   \n",
      "..          ...          ...       ...           ...     ...  ...       ...   \n",
      "995          82       229525     False         0.689   0.481   10    -7.503   \n",
      "996           0       243057     False         0.503   0.582    0    -4.324   \n",
      "997          68       172960     False         0.361   0.871    8    -4.313   \n",
      "998          66       320040     False         0.465   0.822    8    -4.826   \n",
      "999           0       208626     False         0.664   0.783    9    -6.602   \n",
      "\n",
      "     mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
      "0       0       0.0449       0.02820          0.000000    0.1580    0.464   \n",
      "1       0       0.0321       0.92300          0.000034    0.1510    0.446   \n",
      "2       1       0.0487       0.25100          0.003980    0.3220    0.934   \n",
      "3       1       0.0486       0.07010          0.000010    0.1120    0.407   \n",
      "4       1       0.0332       0.44500          0.000129    0.3660    0.775   \n",
      "..    ...          ...           ...               ...       ...      ...   \n",
      "995     1       0.0815       0.36900          0.000001    0.0649    0.283   \n",
      "996     1       0.0253       0.47200          0.000000    0.1030    0.326   \n",
      "997     1       0.0393       0.01190          0.000000    0.3180    0.575   \n",
      "998     0       0.0660       0.13600          0.000442    0.0898    0.405   \n",
      "999     0       0.0321       0.00531          0.327000    0.0245    0.976   \n",
      "\n",
      "       tempo  time_signature track_genre  \n",
      "0    122.872               4         pop  \n",
      "1    129.932               4         pop  \n",
      "2    159.684               4        rock  \n",
      "3     96.968               4     hip-hop  \n",
      "4    114.514               4        rock  \n",
      "..       ...             ...         ...  \n",
      "995   80.025               4         pop  \n",
      "996   77.321               4        rock  \n",
      "997  176.026               4        rock  \n",
      "998   89.761               4         pop  \n",
      "999  100.204               4        rock  \n",
      "\n",
      "[1000 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/spotify_test.csv')\n",
    "train = pd.read_csv('data/spotify_train.csv')\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789\n",
      "1462\n"
     ]
    }
   ],
   "source": [
    "test.drop_duplicates(keep=False, inplace=True,subset=test.columns.difference(['track_genre']))\n",
    "train.drop_duplicates(keep=False, inplace=True, subset=train.columns.difference(['track_genre']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred, y_actual):\n",
    "    correct_cnt = 0\n",
    "    total = len(y_actual)\n",
    "    #assume that y_pred and y_actual have same length\n",
    "\n",
    "    for i in range(len(y_actual)):\n",
    "        pre = y_pred[i]\n",
    "        act = y_actual[i]\n",
    "        if pre == act:\n",
    "            correct_cnt += 1\n",
    "    \n",
    "    return correct_cnt/total\n",
    "\n",
    "def n_folds(folds,train):\n",
    "    for f in range(folds):\n",
    "        train_fold = train[train.index % folds != f]\n",
    "        valid_fold = train[train.index % folds == f]\n",
    "    return train_fold, valid_fold\n",
    "\n",
    "# def tokenize(x):\n",
    "#     #tokenize the predict output to int\n",
    "#     dic = {'hip-hop' : 0, 'pop': 1, 'rock': 2}\n",
    "#     y = dic[x]\n",
    "#     return y\n",
    "\n",
    "# tokenized_pred = np.array(list(map(tokenize, y_pred)))\n",
    "# tokenized_actual = np.array(list(map(tokenize, y_actual)))\n",
    "# print(tokenized_actual)\n",
    "\n",
    "def predict_data(data,tree):\n",
    "    # given a subset dataframe as test data, predict its output alongside with its original answer\n",
    "    y_actual = data['track_genre'].to_numpy()\n",
    "    #apply decision tree prediction to each of the row \n",
    "    y_pred = data.apply(lambda row: tree.predict(row), axis = 1).to_numpy()\n",
    "\n",
    "    return y_actual, y_pred\n",
    "\n",
    "def apply_DTree(train: pd.DataFrame,\n",
    "                validation: pd.DataFrame,\n",
    "                test: pd.DataFrame,\n",
    "                impurity_func: str,\n",
    "                discrete_threshold: int = 10,\n",
    "                max_depth: int = None,\n",
    "                min_instances: int = 2,\n",
    "                target_impurity: float = 0.0\n",
    "                ):\n",
    "    \n",
    "    impurity_func = ml_utils.metric.entropy if impurity_func == 'entropy'   else  ml_utils.metric.gini\n",
    "    tree = ml_utils.experimental.DecisionTree(discrete_threshold=discrete_threshold,\n",
    "                                            max_depth=max_depth,\n",
    "                                            min_instances=min_instances,\n",
    "                                            target_impurity=target_impurity,\n",
    "                                            impurity_func=impurity_func)\n",
    "    tree.train(train,'track_genre')\n",
    "    validation_accuracy = 'N/A'\n",
    "    test_accuracy = 'N/A'\n",
    "    if validation is not None:\n",
    "        validation_accuracy = calc_accuracy(*predict_data(validation,tree))\n",
    "    if test is not None:\n",
    "        test_accuracy = calc_accuracy(*predict_data(test,tree))\n",
    "\n",
    "    return validation_accuracy, test_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: impurity_func: entropy, max_depth: 20, min_instances: 2, target_impurity: 0\n"
     ]
    }
   ],
   "source": [
    "#An example of the accuracy in 10 fold cross validation on trained modal, comparing with accuracy in test data.\n",
    "\n",
    "\n",
    "train_fold, valid_fold = n_folds(10,train)\n",
    "print('Training with: impurity_func: {}, max_depth: {}, min_instances: {}, target_impurity: {}'\n",
    "          .format( 'entropy',20,2,0))\n",
    "validation_accuracy, test_accuracy = apply_DTree(train = train_fold,\n",
    "            validation = valid_fold,\n",
    "            test = test,\n",
    "            impurity_func = 'entropy',\n",
    "            discrete_threshold = 10,\n",
    "            max_depth = 50,\n",
    "            min_instances = 2,\n",
    "            target_impurity = 0)\n",
    "print('Result: Validation accuray: {} || Test accuray: {} \\n'.format(validation_accuracy,test_accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_tuning():\n",
    "    train_fold, valid_fold = n_folds(10,train)\n",
    "    impurity_funcs = ['entorpy']\n",
    "    records = pd.DataFrame(columns= ['impurity_func', 'max_depth', 'min_instances', 'target_impurity','validation_accuracy','test_accuracy'])\n",
    "    for max_depth ,min_instances, target_impurity, impurity_func in product(range(5,30,3), range(2,12,2),np.arange(0,0.2,0.05),impurity_funcs):   \n",
    "                    try:\n",
    "                        validation_accuracy, test_accuracy =apply_DTree(train = train_fold,\n",
    "                                    validation = valid_fold,\n",
    "                                    test = None,\n",
    "                                    impurity_func = impurity_func,\n",
    "                                    discrete_threshold = 10,\n",
    "                                    max_depth = max_depth,\n",
    "                                    min_instances = min_instances,\n",
    "                                    target_impurity = target_impurity)\n",
    "                        row = {'impurity_func': impurity_func, 'max_depth': max_depth, 'min_instances': min_instances, 'target_impurity': target_impurity,'validation_accuracy': validation_accuracy,'test_accuracy': test_accuracy}\n",
    "                        records = pd.concat([records,pd.DataFrame(row,index=[len(records)])])\n",
    "                    except:\n",
    "                        print('Failed with: impurity_func: {}, max_depth: {}, min_instances: {}, target_impurity: {}'.format(impurity_func,max_depth,min_instances,target_impurity))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beef9e9230b94e7991ea1106f6c566f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impurity_func</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_instances</th>\n",
       "      <th>target_impurity</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entorpy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  impurity_func max_depth min_instances  target_impurity  validation_accuracy  \\\n",
       "0       entorpy         2             3              0.0                0.605   \n",
       "1       entorpy         2             3              0.6                0.510   \n",
       "2       entorpy         2             4              0.0                0.605   \n",
       "3       entorpy         2             4              0.6                0.510   \n",
       "4       entorpy         4             3              0.0                0.680   \n",
       "5       entorpy         4             3              0.6                0.510   \n",
       "6       entorpy         4             4              0.0                0.680   \n",
       "7       entorpy         4             4              0.6                0.510   \n",
       "\n",
       "  test_accuracy  \n",
       "0           N/A  \n",
       "1           N/A  \n",
       "2           N/A  \n",
       "3           N/A  \n",
       "4           N/A  \n",
       "5           N/A  \n",
       "6           N/A  \n",
       "7           N/A  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records =para_tuning()\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impurity_func          entorpy\n",
      "max_depth                    6\n",
      "min_instances                3\n",
      "target_impurity              0\n",
      "validation_accuracy      0.775\n",
      "test_accuracy              N/A\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best=records.loc[records['validation_accuracy'].idxmax()]\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: impurity_func: entorpy, max_depth: 6, min_instances: 3, target_impurity: 0\n",
      "Result: Validation accuray: 0.775 || Test accuray: 0.729 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training with: impurity_func: {}, max_depth: {}, min_instances: {}, target_impurity: {}'\n",
    "          .format( best['impurity_func'],best['max_depth'],best['min_instances'],best['target_impurity']))\n",
    "validation_accuracy, test_accuracy = apply_DTree(train = train_fold,\n",
    "            validation = valid_fold,\n",
    "            test = test,\n",
    "            impurity_func = best['impurity_func'],\n",
    "            discrete_threshold = 10,\n",
    "            max_depth = best['max_depth'],\n",
    "            min_instances = best['min_instances'],\n",
    "            target_impurity =  best['target_impurity'])\n",
    "print('Result: Validation accuray: {} || Test accuray: {} \\n'.format(validation_accuracy,test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
